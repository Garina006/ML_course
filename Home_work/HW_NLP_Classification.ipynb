{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнє завдання: Побудова класифікатора сентименту на основі набору даних Tweet Sentiment Extraction\n",
        "\n",
        "**Мета:** Провести аналіз набору даних, виконати векторизацію текстових даних за допомогою методів bag-of-words та TF-IDF, порівняти їх, побудувати класифікатор та провести аналіз помилок.\n",
        "\n",
        "**Набір даних:**\n",
        "Дані беремо з цього змагання на Kaggle: https://www.kaggle.com/competitions/tweet-sentiment-extraction/data?select=train.csv\n",
        "\n",
        "\n",
        "Якщо не вдається завантажиит з Kaggle, ось тут можна - https://drive.google.com/file/d/1kfu5zCRsDHxoBZigBlGIcCieKlws02HT/view?usp=sharing\n",
        "\n",
        "Оригінальне змагання має дещо іншу задачу, але ми будемо поки будувати саме класифікатор.\n",
        "\n",
        "Увага! В цьому наборі завдань для простоти експериментів ми будемо спочатку робити векторизацію на всьому наборі даних, а потім розбивку на train i test. В робочих проєктах ми теж можемо використати цей підхід для швидшої побудови PoC (proof of concept). Але фінальне рішення, яке ми будемо деплоїти - треба проводити за правилом - спочатку розбивка на трейн і тест, потім пишемо обробку для трейну, навчаємо векторизатори. І потім використовуємо готові векторизатори для тесту і всіх даних на етапі передбачення (інференсу).\n",
        "\n",
        "### Завдання 1. Завантаження та ознайомлення з набором даних\n",
        "\n",
        "- Завантажте набір даних `train.csv` з посилання та ознайомтеся з його структурою.\n",
        "- Виведіть перші 5 рядків та основну статистику: кількість записів, типи колонок, кількість пропущених значень.\n",
        "- Видаліть записи, в яких є пропущені значення.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zl1UHn4aRLMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk"
      ],
      "metadata": {
        "id": "wCE1OTPv1Cca"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z9PAZcZgddHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ada1c7f-5403-4e05-90fc-be0f0c0a8071"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls 'drive/MyDrive/ML_Course/Lessons_next'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYoVDOkB0kCD",
        "outputId": "368444c2-e992-4857-d82b-47257034f581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'M_3_1_Методи кластеризації'\t      'М_4_1_Вступ до NLP'\n",
            "'M_3_2_Методи пониження розмірності'  'М_6_Створення додатків на базі LLM'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"drive/MyDrive/ML_Course/Lessons_next/М_4_1_Вступ до NLP/data/tweet_sentiment_train.csv.zip\")"
      ],
      "metadata": {
        "id": "fCydgAg40j_E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WzbiCC-Y0j73",
        "outputId": "c550d108-820e-4dfb-dab4-eed1ea8a0646"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1                I`d have responded, if I were going   \n",
              "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
              "2  088c60f138                          my boss is bullying me...   \n",
              "3  9642c003ef                     what interview! leave me alone   \n",
              "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  \n",
              "0  I`d have responded, if I were going   neutral  \n",
              "1                             Sooo SAD  negative  \n",
              "2                          bullying me  negative  \n",
              "3                       leave me alone  negative  \n",
              "4                        Sons of ****,  negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3902963-10e8-4a51-8e27-334e0df9d337\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3902963-10e8-4a51-8e27-334e0df9d337')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3902963-10e8-4a51-8e27-334e0df9d337 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3902963-10e8-4a51-8e27-334e0df9d337');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c80204d-c4ab-4e15-871b-5ce9c544e17e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c80204d-c4ab-4e15-871b-5ce9c544e17e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c80204d-c4ab-4e15-871b-5ce9c544e17e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 27481,\n  \"fields\": [\n    {\n      \"column\": \"textID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27481,\n        \"samples\": [\n          \"a7f72a928a\",\n          \"ef42dee96c\",\n          \"07d17131b1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27480,\n        \"samples\": [\n          \" Enjoy! Family trumps everything\",\n          \" --of them kinda turns me off of it all.  And then I buy more of them and dig a deeper hole, etc. ;;\",\n          \"Clive it`s my birthday pat me  http://apps.facebook.com/dogbook/profile/view/6386106\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selected_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22463,\n        \"samples\": [\n          \"we win\",\n          \"YES!!! haahaaa.! break out the jellybeaniesss!\",\n          \"hay wats ur AIM? we should chat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg1Ys1H62zD4",
        "outputId": "11a1f599-0db2-4ee0-aa7f-d23cfd4d2e52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27481, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McxO9J6T2kAg",
        "outputId": "f897ca01-e2c9-4a94-debd-c26ceaeffc93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   textID         27481 non-null  object\n",
            " 1   text           27480 non-null  object\n",
            " 2   selected_text  27480 non-null  object\n",
            " 3   sentiment      27481 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 858.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "2GHrSj8H3ACb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет, з яким сьогодні працюємо, має загалом 27481 запис та 4 колоночки. Він складається з id запису, безпосередньо тексту коментаря, виділеної частини з тексту (слово або декілька слів) які і є індикатором сентименту, і безпосередньо лейбли (таргет змінна).  \n",
        "Тип даних для всіх колоночок object, в нашому випадку це текстові значення.  \n",
        "Датасет містив лише 1 запис, що мав пропущені значення в колоночках text та selected_text"
      ],
      "metadata": {
        "id": "3QvRaTUH38ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 2. Exploratory Data Analysis\n",
        "\n",
        "- Проведіть аналіз кількості класів та розподілу міток. Класи знаходяться в колонці `sentiment`.\n",
        "- Візуалізуйте розподіл довжин текстів в символах та зробіть висновок про довжини постів: якої довжини постів найбільше, що бачите з розподілу?\n",
        "\n"
      ],
      "metadata": {
        "id": "BXox7UCZUU5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "aPm_wCjpde0s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "7720b060-2b79-43c7-bb8a-840ad06c49fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     11117\n",
              "positive     8582\n",
              "negative     7781\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>11117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>8582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>7781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таргет змінна має 3 класи.  Найбільша кількість (11117 записів) має клас neutral, positive  та negative мають невеликі відмінності по кількості записів. В цілому, можна вважати що класи, плюс мінус, збалансовані."
      ],
      "metadata": {
        "id": "QTW0gkTA6Jig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'] = df['text'].astype(str).str.len()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "df['text_len'].plot.hist(bins=20, edgecolor='black')\n",
        "plt.xlabel('Довжина, символи')\n",
        "plt.ylabel('Кількість постів')\n",
        "plt.title('Розподіл довжин текстів')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "xMU0MG0P7ViH",
        "outputId": "d632b305-cb29-4635-c2d2-9713c032aeba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'].describe(percentiles=[.25, .50, .75, .80, .90])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "SIXYsYhp74-w",
        "outputId": "5e8695a6-e999-4fd7-cf0e-3c1b32b2e853"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    27480.000000\n",
              "mean        68.330022\n",
              "std         35.603870\n",
              "min          3.000000\n",
              "25%         39.000000\n",
              "50%         64.000000\n",
              "75%         97.000000\n",
              "80%        105.000000\n",
              "90%        122.000000\n",
              "max        141.000000\n",
              "Name: text_len, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27480.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>68.330022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>35.603870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>64.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>97.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80%</th>\n",
              "      <td>105.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90%</th>\n",
              "      <td>122.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>141.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_len'].value_counts().head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "PxPTPm5J-_0v",
        "outputId": "fe081f68-865d-4b7d-8106-218b1e8d3957"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text_len\n",
              "41    308\n",
              "48    301\n",
              "46    301\n",
              "42    298\n",
              "45    295\n",
              "44    294\n",
              "36    293\n",
              "34    292\n",
              "43    291\n",
              "39    291\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text_len</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В середньому, твіти мають 68 символів. Майже 80% твітів мають довжину до 100 символів. Я думаю, що це пов'язано в цілому з обмеженнями на кількість символів, які можна використати за правилами даної соц мережі. Крім того, в твітері дуже розповсюджені скорочення та сленгові слова, які дозволяють скоротити текст. Зовсім коротких твітів, до 20 символів, найменше."
      ],
      "metadata": {
        "id": "KQqqMlcvXeCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 3. Попередня обробка текстових даних та векторизація з bag of words\n",
        "\n",
        "\n",
        "Наша задача тут отримати вектори методом bag of words колонки `text`, виконавши попередню обробку тексту.\n",
        "Попередня обробка має включати\n",
        "- видалення stopwords необхідної мови\n",
        "- токенізація (розбиття текстів на фрагменти по 1 слову)\n",
        "- стеммінг слів зі `SnowballStemmer`.\n",
        "- самостійно задайте кількість слів в словнику для `sklearn.feature_extraction.text.CountVectorizer`. Можливо для цього доведеться виконати додатковий аналіз.\n",
        "\n",
        "Ви також можете додати сюди додаткові методи очистки текстів, наприклад, видалення деяких символів чи груп символів, якщо в процесі роботи побачите, що хочете щось видалити.\n",
        "\n",
        "Напишіть код аби виконати це завдання. Перед цим рекомендую детально ознайомитись з тим, що робить обʼєкт `sklearn.feature_extraction.text.CountVectorizer` за замовченням.\n",
        "\n",
        "Це завдання можна виконати двома способами - один - максимально подібно до того, як ми це робили в лекції, другий - дещо інакше перегрупувавши етапи обробки тексту.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KfiU4hNDWncB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "BRUG111tdhB0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyNR2ueTcQCT",
        "outputId": "d0d21ea1-4612-4421-8dbf-91caf90cc6f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2-2konRc563",
        "outputId": "283c4e16-6194-412a-d420-a6a1bbcabce8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_stopwords = stopwords.words('english')\n",
        "stemmer = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "mFPmbmyGcEYJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    punctuation = string.punctuation.replace('*', '')\n",
        "    text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "kdoNxBW-cEVz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize,\n",
        "    stop_words=english_stopwords\n",
        ")"
      ],
      "metadata": {
        "id": "vG0qsvkMcESl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(df['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4W9x40Fcpkz",
        "outputId": "1dd4bd74-65bf-4f47-cce9-e40f4c2c0581"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'arent', 'becaus', 'befor', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'dure', 'hadnt', 'hasnt', 'havent', 'hed', 'hell', 'hes', 'id', 'ill', 'im', 'isnt', 'itd', 'itll', 'ive', 'mightnt', 'mustnt', 'neednt', 'onc', 'onli', 'ourselv', 'shant', 'shed', 'shell', 'shes', 'shouldnt', 'shouldv', 'thatll', 'themselv', 'theyd', 'theyll', 'theyr', 'theyv', 'veri', 'wasnt', 'wed', 'well', 'werent', 'weve', 'whi', 'wont', 'wouldnt', 'youd', 'youll', 'yourselv', 'youv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorizer.get_feature_names_out()\n",
        "print(f\"Розмір словника: {len(vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjyXqIHTcph5",
        "outputId": "e52b6c21-15ec-48a4-ad92-0a5c77fbdb20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір словника: 24002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip95s5tGfb1L",
        "outputId": "ae0b60fb-56c8-4e82-fafc-70c4ab554c36"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['*', '0', '00', ..., 'ï¿½ï¿½', 'ï¿½ï¿½h', 'ï¿½ï¿½ï¿½ï¿½'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В словнику наявні дивні \"слова\". Дослідимо їх детальніше"
      ],
      "metadata": {
        "id": "4dMMPQ04YuzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = df['text'].astype(str)\n",
        "\n",
        "mask_replacement = s.str.contains(r'\\uFFFD|ï¿½', regex=True)\n",
        "mask_mojibake   = s.str.contains(r'(?:ï¿½){2,}', regex=True)\n",
        "\n",
        "broken_mask = mask_replacement | mask_mojibake\n",
        "\n",
        "non_ascii_mask = s.str.contains(r'[^\\x00-\\x7F]')\n",
        "\n",
        "stats = {\n",
        "    'rows_total': len(s),\n",
        "    'broken_rows': int(broken_mask.sum()),\n",
        "    'broken_share_%': round(100 * broken_mask.mean(), 2),\n",
        "    'non_ascii_share_%': round(100 * non_ascii_mask.mean(), 2),\n",
        "}\n",
        "stats\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG_LZ1POg9Hc",
        "outputId": "33d8e727-9192-4023-80b3-2dcc7bfbbcbe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rows_total': 27480,\n",
              " 'broken_rows': 155,\n",
              " 'broken_share_%': np.float64(0.56),\n",
              " 'non_ascii_share_%': np.float64(0.57)}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = s[broken_mask].head(10).tolist()\n",
        "examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe3IaCEvhKKT",
        "outputId": "b2e3af64-85b1-4ec2-9fb3-3cd4e02193ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½',\n",
              " ' *phew*  Will make a note in case anyone else runs into the same issueï¿½',\n",
              " ' I love mine, too . happy motherï¿½s day to your mom , John Taylor  . much love to you, too .',\n",
              " 'meeting just in time that iï¿½m trying to win something  prize`s friday!',\n",
              " 'Just got confirmed that itï¿½s pizza-time with some ex co-workers on friday...looking forward to it',\n",
              " ' Well thatï¿½s disappointing to hear.',\n",
              " 'today Jon Doe plays at the Moho. ia m excited  itï¿½s gonna be funny.. but before i have to carry all the equipment and do the backline',\n",
              " '_Guy Would luv to hear music too but iï¿½m out of batteries - the tv plays besides but i think this is some kind of vampire movie',\n",
              " 'CCï¿½s video for Long Gone premiers today on yahoo, dont miss it: http://new.music.yahoo.com/videos/premieres/ AWESOME video and version',\n",
              " ' vocï¿½ que sumiu forever do msn.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загалом всього 155 твітів мають в собі такі дивні символи. Якщо аналізувати приклади таких твітів, то можна побачити, що частіше за все так невірно розпізнається апостраф, тобто це \"битий\" символ. Також, можна припустити, що в такі \"биті\" символи входять емодзі."
      ],
      "metadata": {
        "id": "ulfaS-DWY8Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s_sel = df['selected_text'].astype(str)\n",
        "\n",
        "mask_replacement_sel = s_sel.str.contains(r'\\uFFFD|ï¿½', regex=True)\n",
        "mask_mojibake_sel   = s_sel.str.contains(r'(?:ï¿½){2,}', regex=True)\n",
        "\n",
        "broken_sel = mask_replacement_sel | mask_mojibake_sel\n"
      ],
      "metadata": {
        "id": "Pv6V43lhnv6r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_sel = {\n",
        "    'rows_total': len(s_sel),\n",
        "    'broken_rows_selected_text': int(broken_sel.sum()),\n",
        "    'broken_share_%_selected_text': round(100 * broken_sel.mean(), 2),\n",
        "}\n",
        "stats_sel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsZvqIc6nzCM",
        "outputId": "c0de9d3d-5925-4452-9d1b-6d109e616282"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rows_total': 27480,\n",
              " 'broken_rows_selected_text': 76,\n",
              " 'broken_share_%_selected_text': np.float64(0.28)}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[broken_sel, 'sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "gBLL65HhoDy6",
        "outputId": "40cd0ccb-df35-450f-c1f3-8e873cd0f725"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     0.855263\n",
              "positive    0.092105\n",
              "negative    0.052632\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.855263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.092105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.052632</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[~broken_sel, 'sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "PDuH512WoUF9",
        "outputId": "6f4b0132-1640-4cef-91af-f45cc24d9500"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     0.403299\n",
              "positive    0.312911\n",
              "negative    0.283791\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>0.403299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.312911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>0.283791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Як бачимо, найбільша кількість битих (невірних) символів знаходяться саме в твітах з нейтральним забарвленням. Можемо замінити їх на '' - це не має вплинути на подальший аналіз."
      ],
      "metadata": {
        "id": "PPnNquCxZ052"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].astype(str).str.replace(r'(?:ï¿½|\\uFFFD)+', '', regex=True)"
      ],
      "metadata": {
        "id": "tcWIfMLMmOoN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "    return re.sub(r'http\\S+|www\\S+', '', text)"
      ],
      "metadata": {
        "id": "sjWeYDM3vKdj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_without_url(text):\n",
        "    punctuation = string.punctuation.replace('*', '')\n",
        "    text = remove_urls(text)\n",
        "    text = re.sub(f\"[{re.escape(punctuation)}]\", \"\", text)\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "S_CCboE2u9ay"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize_without_url,\n",
        "    stop_words=english_stopwords\n",
        ")\n",
        "X = vectorizer.fit_transform(df['text'])\n",
        "vocab = vectorizer.get_feature_names_out()\n",
        "print(f\"Розмір словника: {len(vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4HfjvFtvRQs",
        "outputId": "97743bf5-c27d-4cc7-ee82-c292fefe843d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'arent', 'becaus', 'befor', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'dure', 'hadnt', 'hasnt', 'havent', 'hed', 'hell', 'hes', 'id', 'ill', 'im', 'isnt', 'itd', 'itll', 'ive', 'mightnt', 'mustnt', 'neednt', 'onc', 'onli', 'ourselv', 'shant', 'shed', 'shell', 'shes', 'shouldnt', 'shouldv', 'thatll', 'themselv', 'theyd', 'theyll', 'theyr', 'theyv', 'veri', 'wasnt', 'wed', 'well', 'werent', 'weve', 'whi', 'wont', 'wouldnt', 'youd', 'youll', 'yourselv', 'youv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір словника: 22644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpoDyfepp71l",
        "outputId": "58f23109-014a-4f34-b20a-043873ae492e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['*', '0', '00', ..., 'zzzzi', 'zzzzzzzgoodnight',\n",
              "       'zzzzzzzzzzzzzzz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Розмір отриманого словника = 22644 слова. Це дуже багато, то ж спробуємо скоротити його для подальшого аналізу"
      ],
      "metadata": {
        "id": "agrFHjcmaW5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "HasqxEu6d4Jy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq = np.asarray(X.sum(axis=0)).ravel()\n",
        "freq_df = (\n",
        "    pd.DataFrame({'word': vocab, 'count': word_freq})\n",
        "      .sort_values(by='count', ascending=False)\n",
        ")\n",
        "print(freq_df.head(60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DI-E70rBdNtk",
        "outputId": "24d9806a-98dc-410c-e12d-fc1aaa3b2d42"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           word  count\n",
            "0             *   4952\n",
            "9977         im   3056\n",
            "5446        day   2370\n",
            "8367         go   2363\n",
            "8191        get   1908\n",
            "8425       good   1569\n",
            "21988      work   1483\n",
            "11960      love   1458\n",
            "11632      like   1454\n",
            "8506        got   1239\n",
            "6098       dont   1202\n",
            "19864     today   1114\n",
            "19757      time   1079\n",
            "14330       one   1055\n",
            "3836       cant   1028\n",
            "9007      happi    993\n",
            "21331      want    981\n",
            "11140      know    969\n",
            "19442     thank    962\n",
            "12905      miss    961\n",
            "11806       lol    951\n",
            "20559         u    923\n",
            "16165    realli    909\n",
            "2269       back    897\n",
            "17223       see    893\n",
            "19580     think    875\n",
            "7252       feel    869\n",
            "13182    mother    788\n",
            "9590       hope    782\n",
            "13747     night    778\n",
            "12228      make    751\n",
            "21552      well    746\n",
            "13654       new    740\n",
            "9508       home    725\n",
            "11872      look    715\n",
            "13443        na    703\n",
            "13574      need    695\n",
            "18600     still    679\n",
            "294           2    666\n",
            "14198        oh    664\n",
            "13296      much    660\n",
            "21389     watch    646\n",
            "4672       come    624\n",
            "8615      great    617\n",
            "21858      wish    612\n",
            "11370      last    594\n",
            "13129      morn    569\n",
            "8862       haha    555\n",
            "20464   twitter    551\n",
            "16892       sad    544\n",
            "21493      week    541\n",
            "9951        ill    537\n",
            "7902        fun    527\n",
            "19942  tomorrow    507\n",
            "22065     would    503\n",
            "17054       say    495\n",
            "2307        bad    491\n",
            "19571     thing    488\n",
            "21676       whi    488\n",
            "20190       tri    487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для подальших експериментів, визначимо, яка кількість слів покриває 90% всіх твітів, щоб спробувати визначити необхідну кількість слів (фіч)"
      ],
      "metadata": {
        "id": "qHI_l-bwaw2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_df = freq_df.sort_values(by='count', ascending=False)\n",
        "freq_df['cum_sum'] = freq_df['count'].cumsum()\n",
        "freq_df['cum_perc'] = freq_df['cum_sum'] / freq_df['count'].sum()\n",
        "\n",
        "n_words_90 = freq_df[freq_df['cum_perc'] <= 0.9].shape[0]\n",
        "print(f\"Щоб покрити 90% усіх вживань, потрібно {n_words_90} слів.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0SwuEdcfKno",
        "outputId": "49b689a3-49ce-419d-9c3a-6e7c44c01e22"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Щоб покрити 90% усіх вживань, потрібно 5297 слів.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для порівняння різних підходів, спробуємо векторизувати наші твіти трьома способами."
      ],
      "metadata": {
        "id": "-2fWJNcWbGOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_features = 6000 слів (покривають 90% всіх твітів)"
      ],
      "metadata": {
        "id": "wR_RBTJnsp3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_max_feat = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize_without_url,\n",
        "    stop_words=english_stopwords,\n",
        "    max_features=6000\n",
        ")\n",
        "X_max_feat = vectorizer_max_feat.fit_transform(df['text'])\n",
        "vocab_max_feat = vectorizer_max_feat.get_feature_names_out()\n",
        "print(f\"Розмір словника: {len(vocab_max_feat)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJRLms_DqjmC",
        "outputId": "8d4ab9e5-f8b4-4074-fd79-081e394dd838"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'arent', 'becaus', 'befor', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'dure', 'hadnt', 'hasnt', 'havent', 'hed', 'hell', 'hes', 'id', 'ill', 'im', 'isnt', 'itd', 'itll', 'ive', 'mightnt', 'mustnt', 'neednt', 'onc', 'onli', 'ourselv', 'shant', 'shed', 'shell', 'shes', 'shouldnt', 'shouldv', 'thatll', 'themselv', 'theyd', 'theyll', 'theyr', 'theyv', 'veri', 'wasnt', 'wed', 'well', 'werent', 'weve', 'whi', 'wont', 'wouldnt', 'youd', 'youll', 'yourselv', 'youv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір словника: 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прибираємо слова, що зустрічаються рідше 2 разів"
      ],
      "metadata": {
        "id": "yUK-Tx2ystZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_min_df = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize_without_url,\n",
        "    stop_words=english_stopwords,\n",
        "    min_df=2\n",
        ")\n",
        "X_min_df = vectorizer_min_df.fit_transform(df['text'])\n",
        "vocab_min_df = vectorizer_min_df.get_feature_names_out()\n",
        "print(f\"Розмір словника: {len(vocab_min_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-QIYDdPqdnX",
        "outputId": "83a9b52a-a962-4015-dfd3-e5555a842739"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір словника: 8148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "max_features = 2000 слів"
      ],
      "metadata": {
        "id": "D86Z3FGxba2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_min = CountVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize_without_url,\n",
        "    stop_words=english_stopwords,\n",
        "    max_features=2000\n",
        ")\n",
        "X_min = vectorizer_min.fit_transform(df['text'])\n",
        "vocab_min = vectorizer_min.get_feature_names_out()\n",
        "print(f\"Розмір словника: {len(vocab_min)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSbAK59HsG9Y",
        "outputId": "d07135d7-8600-41a1-d669-97c34e712c80"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Розмір словника: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 4. Побудова класифікатора\n",
        "\n",
        "- Розділіть індекси даних на навчальний та тестовий набори в обраному співвівдношенні. Використовуючи отримані індекси сфомуйте набори для тренування класифікатора `X_train_bow, X_test_bow, y_train, y_test`.\n",
        "- Навчіть класифікатор (наприклад, Logistic Regression, Decision Tree або один з алгоритмів бустингу) на даних, векторизованих методом bag-of-words. Спробуйте кілька моделей і оберіть найбільш точну :)\n",
        "- Виведіть інформацію, яка дає можливість оцінити якість класифікації.\n",
        "- Оцініть якість фінальної класифікації: вона хороша чи не дуже?\n",
        "\n"
      ],
      "metadata": {
        "id": "v0RHDwO7OBIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "66dgL8ROzIzG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['sentiment']"
      ],
      "metadata": {
        "id": "zOcwwg9Jz08a"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набори для 6000 слів"
      ],
      "metadata": {
        "id": "cBfbgBOJzwUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_max_feat, X_test_max_feat, y_train_max_feat, y_test_max_feat = train_test_split(\n",
        "    X_max_feat,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "aXZes5Zpzqb7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набори для 8148 слів"
      ],
      "metadata": {
        "id": "8a3WKc6Szq2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_min_df, X_test_min_df, y_train_min_df, y_test_min_df = train_test_split(\n",
        "    X_min_df,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "MIDnTq3CzqIt"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Набори для 2000 слів"
      ],
      "metadata": {
        "id": "X9iMScrCzmiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_min, X_test_min, y_train_min, y_test_min = train_test_split(\n",
        "    X_min,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "NVdpanFFdkyo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "BdMuZ68z1MSm"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "Gzot-ko91arV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренуємо модель для 6000 ознак"
      ],
      "metadata": {
        "id": "Wt9kNiCI6FS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_max_feat, y_train_max_feat)\n",
        "    y_pred = model.predict(X_test_max_feat)\n",
        "\n",
        "    acc = accuracy_score(y_test_max_feat, y_pred)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test_max_feat, y_pred, digits=3))\n",
        "    results[name] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8LQTrF11aoe",
        "outputId": "23f74d3b-d311-436a-d6a8-d83c0274c4a3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.6832\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.694     0.626     0.659      2334\n",
            "     neutral      0.631     0.712     0.669      3335\n",
            "    positive      0.755     0.697     0.725      2575\n",
            "\n",
            "    accuracy                          0.683      8244\n",
            "   macro avg      0.694     0.679     0.684      8244\n",
            "weighted avg      0.688     0.683     0.684      8244\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.6371\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.611     0.631     0.621      2334\n",
            "     neutral      0.627     0.597     0.612      3335\n",
            "    positive      0.672     0.694     0.683      2575\n",
            "\n",
            "    accuracy                          0.637      8244\n",
            "   macro avg      0.637     0.641     0.639      8244\n",
            "weighted avg      0.637     0.637     0.637      8244\n",
            "\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.6593\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.757     0.467     0.577      2334\n",
            "     neutral      0.577     0.821     0.678      3335\n",
            "    positive      0.779     0.625     0.694      2575\n",
            "\n",
            "    accuracy                          0.659      8244\n",
            "   macro avg      0.704     0.637     0.650      8244\n",
            "weighted avg      0.691     0.659     0.654      8244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренуємо модель для 8148 ознак"
      ],
      "metadata": {
        "id": "BRqpuUsJ6Mzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_min_df, y_train_min_df)\n",
        "    y_pred = model.predict(X_test_min_df)\n",
        "\n",
        "    acc = accuracy_score(y_test_min_df, y_pred)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test_min_df, y_pred, digits=3))\n",
        "    results[name] = acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6I-BMiB1ak2",
        "outputId": "842d2029-417d-4abb-e5b6-26f829e3277b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.6816\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.690     0.627     0.657      2334\n",
            "     neutral      0.629     0.710     0.667      3335\n",
            "    positive      0.757     0.694     0.724      2575\n",
            "\n",
            "    accuracy                          0.682      8244\n",
            "   macro avg      0.692     0.677     0.683      8244\n",
            "weighted avg      0.686     0.682     0.682      8244\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.6397\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.612     0.622     0.617      2334\n",
            "     neutral      0.635     0.597     0.615      3335\n",
            "    positive      0.670     0.711     0.690      2575\n",
            "\n",
            "    accuracy                          0.640      8244\n",
            "   macro avg      0.639     0.643     0.641      8244\n",
            "weighted avg      0.639     0.640     0.639      8244\n",
            "\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.6589\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.754     0.468     0.577      2334\n",
            "     neutral      0.578     0.819     0.677      3335\n",
            "    positive      0.778     0.625     0.693      2575\n",
            "\n",
            "    accuracy                          0.659      8244\n",
            "   macro avg      0.703     0.637     0.649      8244\n",
            "weighted avg      0.690     0.659     0.654      8244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тренуємо модель для 2000 ознак"
      ],
      "metadata": {
        "id": "RopEDUi36Qom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_min, y_train_min)\n",
        "    y_pred = model.predict(X_test_min)\n",
        "\n",
        "    acc = accuracy_score(y_test_min, y_pred)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test_min, y_pred, digits=3))\n",
        "    results[name] = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7doOpmlS1ahn",
        "outputId": "12a66a6d-d05d-4209-f938-c86bfb02d2ef"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.6836\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.700     0.611     0.653      2334\n",
            "     neutral      0.628     0.726     0.673      3335\n",
            "    positive      0.761     0.694     0.726      2575\n",
            "\n",
            "    accuracy                          0.684      8244\n",
            "   macro avg      0.696     0.677     0.684      8244\n",
            "weighted avg      0.690     0.684     0.684      8244\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.6274\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.597     0.609     0.603      2334\n",
            "     neutral      0.618     0.589     0.603      3335\n",
            "    positive      0.666     0.693     0.679      2575\n",
            "\n",
            "    accuracy                          0.627      8244\n",
            "   macro avg      0.627     0.631     0.628      8244\n",
            "weighted avg      0.627     0.627     0.627      8244\n",
            "\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.6582\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.764     0.461     0.575      2334\n",
            "     neutral      0.575     0.822     0.677      3335\n",
            "    positive      0.776     0.626     0.693      2575\n",
            "\n",
            "    accuracy                          0.658      8244\n",
            "   macro avg      0.705     0.636     0.648      8244\n",
            "weighted avg      0.692     0.658     0.653      8244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "За результатами оцінки якості натренованих моделей, можна сказати, що Logistic Regression на 2000 слів відпрацювала найкраще.  \n",
        "1. Маємо найвищий показник точності 0.684, макро та зважений f1, з таким самим значенням. Це означає, що модель непогано тримає баланс між всіма класами. Немає прям явного перекосу в домінуючий клас.  \n",
        "2. f1 по кожному класу окремо так само на найвищому рівні.  \n",
        "3. precision / recall: модель дуже непогано визначає positive клас, знаходить багато neutral твітів (recall 0.726) але частіше плутає їх з іншими класами. Трохи обережніша з визначенням negative твітів, проте все ще знахидить 60%.  \n",
        "4. Використаний простіший словник, отже менше ризику переобучення, менше пам’яті, швидше навчання."
      ],
      "metadata": {
        "id": "fRmA7St1hAN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 5. Аналіз впливовості слів в отриманого класифікатора\n",
        "\n",
        "- Для обраної вами моделі проведіть аналіз важливості слів (ознак): які слова (токени) найбільше впливають для визначення сентименту? Чи це логічно на ваш погляд, що саме ці символи впливають найбільше/найменще?\n"
      ],
      "metadata": {
        "id": "53hZa4bKP5Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.Series(results['Logistic Regression'].coef_[0], index=vectorizer_min.get_feature_names_out(), name='imp').sort_values(ascending=False)\n",
        "feature_importance"
      ],
      "metadata": {
        "id": "z0YBHvG4dmKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "4c6d1f62-43ca-41dd-935a-fe23bf4139a8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sad       2.567593\n",
              "suck      2.483479\n",
              "hate      2.241413\n",
              "sorri     2.182142\n",
              "bore      2.160790\n",
              "            ...   \n",
              "thank    -2.014120\n",
              "beauti   -2.054504\n",
              "love     -2.207028\n",
              "glad     -2.242284\n",
              "awesom   -2.327268\n",
              "Name: imp, Length: 2000, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>2.567593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suck</th>\n",
              "      <td>2.483479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hate</th>\n",
              "      <td>2.241413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sorri</th>\n",
              "      <td>2.182142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bore</th>\n",
              "      <td>2.160790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thank</th>\n",
              "      <td>-2.014120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beauti</th>\n",
              "      <td>-2.054504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>-2.207028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glad</th>\n",
              "      <td>-2.242284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>awesom</th>\n",
              "      <td>-2.327268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "З виведених коефіцієнтів важливості слів, можемо прослідкувати чітку відмінність і логічність в наборах, що впливають на вибір negative та positive класів."
      ],
      "metadata": {
        "id": "_i3-mig9qOI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance[(feature_importance >= -0.5) & (feature_importance <= 0.5)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "oetKRDhJrPaV",
        "outputId": "8da98af1-e52f-46c0-d287-863f8ee3ea4f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ohh        0.499504\n",
              "swollen    0.499234\n",
              "knee       0.496518\n",
              "cnt        0.496071\n",
              "fruit      0.494322\n",
              "             ...   \n",
              "pic       -0.494210\n",
              "video     -0.496768\n",
              "14        -0.497224\n",
              "da        -0.497226\n",
              "ps        -0.497335\n",
              "Name: imp, Length: 1454, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ohh</th>\n",
              "      <td>0.499504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swollen</th>\n",
              "      <td>0.499234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knee</th>\n",
              "      <td>0.496518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cnt</th>\n",
              "      <td>0.496071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fruit</th>\n",
              "      <td>0.494322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pic</th>\n",
              "      <td>-0.494210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>video</th>\n",
              "      <td>-0.496768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.497224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>da</th>\n",
              "      <td>-0.497226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ps</th>\n",
              "      <td>-0.497335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1454 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Як бачимо, слова, що мають значно менші коефіцієнти важливості, не несуть в собі явного сентиментального забарвлення (ані позитивного, ані негативного)"
      ],
      "metadata": {
        "id": "hPPU5ansseSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 6. Векторизація текстів з допомогою TF-IDF. Тренування класифікатора, аналіз точності і впливовості слів.\n",
        "\n",
        "- Проведіть векторизацію текстів з векторизатором TfidfVectorizer. Реалізуйте векторизацію так, аби препроцесинг включав всі ті самі кроки, що і в випадку використання векторизації Bag of Words.\n",
        "\n",
        "- Натренуйте той самий класифікатор на TF-IDF векторах, виконавши розбивку набору даних на train, test так, аби в трейні були всі ті самі записи, що і були в попередньому завданні (це важливо для порівняння результатів).\n",
        "\n",
        "- Проаналізуйте якість класифікації вивівши потрібні для цього метрики. Чи стала якість класифікації кращою?\n",
        "\n",
        "- Які токени найбільше впливають на результат при тренуваннні класифікатора з TF-IDF векторами? Порівняйте з найважливішими токенами при Bag of Words векторизації. Яку векторизацію ви б обрали для фінальної імплементації рішення? Обґрунтуйте свій вибір.\n",
        "\n"
      ],
      "metadata": {
        "id": "FvJlvr9JRhzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "huUPpVhMdodx"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    lowercase=True,\n",
        "    tokenizer=tokenize_without_url,\n",
        "    stop_words=english_stopwords,\n",
        "    max_features=2000\n",
        ")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['text'])\n",
        "vocab_tfidf = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ5ZoglEtHSK",
        "outputId": "7d086a4f-f852-4fc5-8bea-553a1aaf4a1b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'arent', 'becaus', 'befor', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'dure', 'hadnt', 'hasnt', 'havent', 'hed', 'hell', 'hes', 'id', 'ill', 'im', 'isnt', 'itd', 'itll', 'ive', 'mightnt', 'mustnt', 'neednt', 'onc', 'onli', 'ourselv', 'shant', 'shed', 'shell', 'shes', 'shouldnt', 'shouldv', 'thatll', 'themselv', 'theyd', 'theyll', 'theyr', 'theyv', 'veri', 'wasnt', 'wed', 'well', 'werent', 'weve', 'whi', 'wont', 'wouldnt', 'youd', 'youll', 'yourselv', 'youv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = X_min.shape[0]\n",
        "idx = np.arange(n)\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    idx,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "X_train = X_tfidf[train_idx]\n",
        "X_test  = X_tfidf[test_idx]\n",
        "y_arr  = y.to_numpy() if hasattr(y, \"to_numpy\") else np.asarray(y)\n",
        "y_train = y_arr[train_idx]\n",
        "y_test  = y_arr[test_idx]"
      ],
      "metadata": {
        "id": "IKDRQsD0tHJy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model_tfidf.fit(X_train, y_train)\n",
        "y_pred = model_tfidf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test_min, y_pred, digits=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSWjn_Vi2V-j",
        "outputId": "1c1d46a0-242e-455c-a7eb-dc5182163e40"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative      0.710     0.611     0.656      2334\n",
            "     neutral      0.628     0.743     0.681      3335\n",
            "    positive      0.773     0.687     0.728      2575\n",
            "\n",
            "    accuracy                          0.688      8244\n",
            "   macro avg      0.704     0.680     0.688      8244\n",
            "weighted avg      0.696     0.688     0.688      8244\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_tfidf = pd.Series(model_tfidf.coef_[0], index=tfidf_vectorizer.get_feature_names_out(), name='imp').sort_values(ascending=False)\n",
        "feature_importance_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "hV3fY80Z4VTI",
        "outputId": "e3a8cff7-5fde-428e-bf2f-8bfedf726eba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sad       4.900572\n",
              "miss      4.561840\n",
              "hate      4.222294\n",
              "sorri     4.145863\n",
              "suck      4.142890\n",
              "            ...   \n",
              "glad     -2.872952\n",
              "hope     -3.155094\n",
              "awesom   -3.423780\n",
              "thank    -3.700186\n",
              "love     -4.982504\n",
              "Name: imp, Length: 2000, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>4.900572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>miss</th>\n",
              "      <td>4.561840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hate</th>\n",
              "      <td>4.222294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sorri</th>\n",
              "      <td>4.145863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suck</th>\n",
              "      <td>4.142890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>glad</th>\n",
              "      <td>-2.872952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hope</th>\n",
              "      <td>-3.155094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>awesom</th>\n",
              "      <td>-3.423780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thank</th>\n",
              "      <td>-3.700186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>love</th>\n",
              "      <td>-4.982504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель натренована з Tf-IDF показала кращі результати.  \n",
        "1. Збільшилась точність до 0.69, а також макро та зважений f1\n",
        "2. Класові f1 також збільшились по всіх класах.\n",
        "3. Коефіцієнти важливості слів залишаються так само логічними і зрозумілими"
      ],
      "metadata": {
        "id": "-Hix2myY-aog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Завдання 7. Аналіз помилок класифікації з векторизацією TF-IDF.\n",
        "\n",
        "- Проаналізуйте, на яких екземплярах помиляється класифікатор при векторизації TF-IDF.\n",
        "- На основі аналізу запропонуйте 3 шляхи поліпшення якості класифікації."
      ],
      "metadata": {
        "id": "3zsp9KftOqyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['predicts'] = model_tfidf.predict(X_min)"
      ],
      "metadata": {
        "id": "RbnvtiL8Y-D-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['error'] = df.sentiment != df.predicts"
      ],
      "metadata": {
        "id": "NAMNzY_lBIb_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['error'] == 1]['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "nQsYFiqQDQY7",
        "outputId": "0d2aa9f4-eff4-4358-ef4b-d2364cded9a9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "neutral     5166\n",
              "negative    1754\n",
              "positive    1239\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>1754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['error'] == 1].head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dDREnKFkBQ10",
        "outputId": "5de0139f-1363-4407-a516-a1b98cc64bdb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         textID                                               text  \\\n",
              "2    088c60f138                          my boss is bullying me...   \n",
              "3    9642c003ef                     what interview! leave me alone   \n",
              "5    28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
              "7    50e14c0bb8                                         Soooo high   \n",
              "10   2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
              "12   74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
              "20   04d17ef61e   oh Marly, I`m so sorry!!  I hope you find her...   \n",
              "24   0c8cc71c46  SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...   \n",
              "27   bdc32ea43c  On the way to Malaysia...no internet access to...   \n",
              "29   d22e6d40a7  Went to sleep and there is a power cut in Noid...   \n",
              "30   d33f811375  I`m going home now. Have you seen my new twitt...   \n",
              "32   1c31703aef   If it is any consolation I got my BMI tested ...   \n",
              "34   d21ab5855b   Ahhh, I slept through the game.  I`m gonna tr...   \n",
              "37   1cbc812ece  just in case you wonder, we are really busy to...   \n",
              "38   4b61dffbeb  i`m soooooo sleeeeepy!!! the last day o` schoo...   \n",
              "40   d93afa85cf   Car not happy, big big dent in boot! Hoping t...   \n",
              "43   684081e4e7  RATT ROCKED NASHVILLE TONITE..ONE THING SUCKED...   \n",
              "45   a9d499e123  The girl in the hair salon asked me 'Shall I t...   \n",
              "49   3fcea4debc   which case? I got a new one last week and I`m...   \n",
              "50   a3ae670885   Then you should check out http://twittersucks...   \n",
              "51   15d5f3a41b   also bored at school, its my third freelesson...   \n",
              "58   703afdc44b                 Aw. Torn ace of hearts  #Hunchback   \n",
              "59   90f3d2b572                      what fun are you speaking of?   \n",
              "61   a4b0888da6                                           haha yes   \n",
              "62   2a9765b7f9                                I give in to easily   \n",
              "67   c34feef039  Yay playing a show tonight! Boo it`s gonna sog...   \n",
              "68   fa2654e730                                           Chilliin   \n",
              "73   0c4aa867d0  'you can ride one, you can catch one, but its ...   \n",
              "74   a6c61eac26   she is good! so gor-juz yea i kno i asked her...   \n",
              "76   35f393a245  WOW, i AM REALLY MiSSiN THE FAM(iLY) TODAY. BA...   \n",
              "82   cb4d439ebc                   fell asleep waiting for my ride!   \n",
              "86   0c0563423e   Miles from you   I`m in Essex so give me plen...   \n",
              "87   cd0d522bb1  His snoring is so annoying n it keeps me from ...   \n",
              "88   bffa3ddd61  i miss you bby      wish you were going tomorr...   \n",
              "92   a3de81e1ba   Hi  how are you doing ???  *just joined twitt...   \n",
              "96   61a8e11e8a   CASEY`S GONE?!?! BUT WHY?! So, she piddled a ...   \n",
              "103  fd9fb4f1ad  i realy wanted to go out cause its so nice but...   \n",
              "106  d0d3c6f298   cool i wear black most of the time when i go out   \n",
              "108  561b44a42f   have a safe trip joshy poo.......you`ll knock...   \n",
              "117  9843c4688e                              hahaa your awesomee !   \n",
              "118  87fbf14655    holy smokes! star trek was freaking awesomeeeee   \n",
              "119  22d1806fa0  I hate Fallout 3 it keeps making me jump, I`m ...   \n",
              "120  9d2cffd953   I had it! On my itunes, but then I lost all m...   \n",
              "121  f78761f7ec  What`s with the gloomy weather? The sun must b...   \n",
              "124  f0460d611d                                           not well   \n",
              "125  6649f3558c                                     Not a prob hun   \n",
              "132  b495300bbf   those splinters look very painful...but you w...   \n",
              "137  ef74bab7f3   Congrats!  I cuss like that in a matter of mi...   \n",
              "140  3e67a75303  Today is going to be a normal day for I hope. ...   \n",
              "141  997a62f83f  These kids are terrible! If I was in Good Evan...   \n",
              "\n",
              "                                         selected_text sentiment  text_len  \\\n",
              "2                                          bullying me  negative        25   \n",
              "3                                       leave me alone  negative        31   \n",
              "5    http://www.dothebouncy.com/smf - some shameles...   neutral        92   \n",
              "7                                           Soooo high   neutral        10   \n",
              "10   as much as i love to be hopeful, i reckon the ...   neutral       107   \n",
              "12                                         DANGERously  negative        44   \n",
              "20   oh Marly, I`m so sorry!!  I hope you find her ...   neutral        59   \n",
              "24   SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...   neutral        79   \n",
              "27                                        .no internet  negative        51   \n",
              "29                       Power back up not working too  negative        78   \n",
              "30                                   Quite....heavenly  positive        84   \n",
              "32   well so much for being unhappy for about 10 mi...  negative       126   \n",
              "34   Ahhh, I slept through the game.  I`m gonna try...   neutral       102   \n",
              "37   just in case you wonder, we are really busy to...   neutral       123   \n",
              "38                                soooooo sleeeeepy!!!  negative        72   \n",
              "40   Car not happy, big big dent in boot! Hoping th...   neutral       107   \n",
              "43   RATT ROCKED NASHVILLE TONITE..ONE THING SUCKED...   neutral       138   \n",
              "45   The girl in the hair salon asked me 'Shall I t...   neutral        84   \n",
              "49                d I`m not thrilled at all with mine.  negative        77   \n",
              "50   Then you should check out http://twittersucks....   neutral        98   \n",
              "51   also bored at school, its my third freelesson(...   neutral        60   \n",
              "58                                  Torn ace of hearts  negative        34   \n",
              "59                       what fun are you speaking of?   neutral        30   \n",
              "61                                            haha yes   neutral         9   \n",
              "62                                 I give in to easily  negative        19   \n",
              "67   Yay playing a show tonight! Boo it`s gonna sog...   neutral        85   \n",
              "68                                            Chilliin  positive         8   \n",
              "73   'you can ride one, you can catch one, but its ...   neutral        81   \n",
              "74   she is good! so gor-juz yea i kno i asked her ...   neutral       120   \n",
              "76                                              BADDD.  negative        50   \n",
              "82                    fell asleep waiting for my ride!   neutral        32   \n",
              "86   Miles from you   I`m in Essex so give me plent...   neutral       124   \n",
              "87   His snoring is so annoying n it keeps me from ...   neutral       131   \n",
              "88                                      i miss you bby  negative        68   \n",
              "92   Hi  how are you doing ???  *just joined twitte...   neutral        52   \n",
              "96                                             freaked  negative       125   \n",
              "103                                               busy  negative        62   \n",
              "106   cool i wear black most of the time when i go out   neutral        49   \n",
              "108                                               safe  positive        71   \n",
              "117                              hahaa your awesomee !  positive        22   \n",
              "118                                        awesomeeeee  positive        47   \n",
              "119  I hate Fallout 3 it keeps making me jump, I`m ...   neutral       120   \n",
              "120  I had it! On my itunes, but then I lost all my...   neutral        54   \n",
              "121  What`s with the gloomy weather? The sun must b...   neutral       134   \n",
              "124                                           not well  negative         8   \n",
              "125                                         Not a prob  positive        15   \n",
              "132                                           painful.  negative        85   \n",
              "137  Congrats!  I cuss like that in a matter of min...   neutral       104   \n",
              "140  Today is going to be a normal day for I hope. ...   neutral       135   \n",
              "141                                          terrible!  negative        67   \n",
              "\n",
              "     predicts  error  \n",
              "2     neutral   True  \n",
              "3    positive   True  \n",
              "5    positive   True  \n",
              "7    negative   True  \n",
              "10   positive   True  \n",
              "12    neutral   True  \n",
              "20   positive   True  \n",
              "24   negative   True  \n",
              "27    neutral   True  \n",
              "29    neutral   True  \n",
              "30   negative   True  \n",
              "32   positive   True  \n",
              "34   positive   True  \n",
              "37   positive   True  \n",
              "38   positive   True  \n",
              "40   positive   True  \n",
              "43   negative   True  \n",
              "45   negative   True  \n",
              "49    neutral   True  \n",
              "50   negative   True  \n",
              "51   negative   True  \n",
              "58    neutral   True  \n",
              "59   positive   True  \n",
              "61   positive   True  \n",
              "62    neutral   True  \n",
              "67   positive   True  \n",
              "68    neutral   True  \n",
              "73   negative   True  \n",
              "74   positive   True  \n",
              "76   positive   True  \n",
              "82   positive   True  \n",
              "86   negative   True  \n",
              "87   positive   True  \n",
              "88   positive   True  \n",
              "92   negative   True  \n",
              "96    neutral   True  \n",
              "103  positive   True  \n",
              "106  positive   True  \n",
              "108  negative   True  \n",
              "117   neutral   True  \n",
              "118   neutral   True  \n",
              "119  negative   True  \n",
              "120  negative   True  \n",
              "121  negative   True  \n",
              "124   neutral   True  \n",
              "125   neutral   True  \n",
              "132  positive   True  \n",
              "137  positive   True  \n",
              "140  positive   True  \n",
              "141  positive   True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c3305ab-39fa-4e1b-bfbb-bb0fe7319b73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_len</th>\n",
              "      <th>predicts</th>\n",
              "      <th>error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>25</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>31</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28b57f3990</td>\n",
              "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
              "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>92</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>50e14c0bb8</td>\n",
              "      <td>Soooo high</td>\n",
              "      <td>Soooo high</td>\n",
              "      <td>neutral</td>\n",
              "      <td>10</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2339a9b08b</td>\n",
              "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
              "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>107</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74a76f6e0a</td>\n",
              "      <td>My Sharpie is running DANGERously low on ink</td>\n",
              "      <td>DANGERously</td>\n",
              "      <td>negative</td>\n",
              "      <td>44</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>04d17ef61e</td>\n",
              "      <td>oh Marly, I`m so sorry!!  I hope you find her...</td>\n",
              "      <td>oh Marly, I`m so sorry!!  I hope you find her ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>59</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0c8cc71c46</td>\n",
              "      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n",
              "      <td>SEe waT I Mean bOuT FoLL0w fRiiDaYs... It`S cA...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>79</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>bdc32ea43c</td>\n",
              "      <td>On the way to Malaysia...no internet access to...</td>\n",
              "      <td>.no internet</td>\n",
              "      <td>negative</td>\n",
              "      <td>51</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>d22e6d40a7</td>\n",
              "      <td>Went to sleep and there is a power cut in Noid...</td>\n",
              "      <td>Power back up not working too</td>\n",
              "      <td>negative</td>\n",
              "      <td>78</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>d33f811375</td>\n",
              "      <td>I`m going home now. Have you seen my new twitt...</td>\n",
              "      <td>Quite....heavenly</td>\n",
              "      <td>positive</td>\n",
              "      <td>84</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1c31703aef</td>\n",
              "      <td>If it is any consolation I got my BMI tested ...</td>\n",
              "      <td>well so much for being unhappy for about 10 mi...</td>\n",
              "      <td>negative</td>\n",
              "      <td>126</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>d21ab5855b</td>\n",
              "      <td>Ahhh, I slept through the game.  I`m gonna tr...</td>\n",
              "      <td>Ahhh, I slept through the game.  I`m gonna try...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>102</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1cbc812ece</td>\n",
              "      <td>just in case you wonder, we are really busy to...</td>\n",
              "      <td>just in case you wonder, we are really busy to...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>123</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4b61dffbeb</td>\n",
              "      <td>i`m soooooo sleeeeepy!!! the last day o` schoo...</td>\n",
              "      <td>soooooo sleeeeepy!!!</td>\n",
              "      <td>negative</td>\n",
              "      <td>72</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>d93afa85cf</td>\n",
              "      <td>Car not happy, big big dent in boot! Hoping t...</td>\n",
              "      <td>Car not happy, big big dent in boot! Hoping th...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>107</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>684081e4e7</td>\n",
              "      <td>RATT ROCKED NASHVILLE TONITE..ONE THING SUCKED...</td>\n",
              "      <td>RATT ROCKED NASHVILLE TONITE..ONE THING SUCKED...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>138</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>a9d499e123</td>\n",
              "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
              "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>84</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>3fcea4debc</td>\n",
              "      <td>which case? I got a new one last week and I`m...</td>\n",
              "      <td>d I`m not thrilled at all with mine.</td>\n",
              "      <td>negative</td>\n",
              "      <td>77</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>a3ae670885</td>\n",
              "      <td>Then you should check out http://twittersucks...</td>\n",
              "      <td>Then you should check out http://twittersucks....</td>\n",
              "      <td>neutral</td>\n",
              "      <td>98</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>15d5f3a41b</td>\n",
              "      <td>also bored at school, its my third freelesson...</td>\n",
              "      <td>also bored at school, its my third freelesson(...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>60</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>703afdc44b</td>\n",
              "      <td>Aw. Torn ace of hearts  #Hunchback</td>\n",
              "      <td>Torn ace of hearts</td>\n",
              "      <td>negative</td>\n",
              "      <td>34</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>90f3d2b572</td>\n",
              "      <td>what fun are you speaking of?</td>\n",
              "      <td>what fun are you speaking of?</td>\n",
              "      <td>neutral</td>\n",
              "      <td>30</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>a4b0888da6</td>\n",
              "      <td>haha yes</td>\n",
              "      <td>haha yes</td>\n",
              "      <td>neutral</td>\n",
              "      <td>9</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>2a9765b7f9</td>\n",
              "      <td>I give in to easily</td>\n",
              "      <td>I give in to easily</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>c34feef039</td>\n",
              "      <td>Yay playing a show tonight! Boo it`s gonna sog...</td>\n",
              "      <td>Yay playing a show tonight! Boo it`s gonna sog...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>85</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>fa2654e730</td>\n",
              "      <td>Chilliin</td>\n",
              "      <td>Chilliin</td>\n",
              "      <td>positive</td>\n",
              "      <td>8</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0c4aa867d0</td>\n",
              "      <td>'you can ride one, you can catch one, but its ...</td>\n",
              "      <td>'you can ride one, you can catch one, but its ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>81</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>a6c61eac26</td>\n",
              "      <td>she is good! so gor-juz yea i kno i asked her...</td>\n",
              "      <td>she is good! so gor-juz yea i kno i asked her ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>120</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>35f393a245</td>\n",
              "      <td>WOW, i AM REALLY MiSSiN THE FAM(iLY) TODAY. BA...</td>\n",
              "      <td>BADDD.</td>\n",
              "      <td>negative</td>\n",
              "      <td>50</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>cb4d439ebc</td>\n",
              "      <td>fell asleep waiting for my ride!</td>\n",
              "      <td>fell asleep waiting for my ride!</td>\n",
              "      <td>neutral</td>\n",
              "      <td>32</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0c0563423e</td>\n",
              "      <td>Miles from you   I`m in Essex so give me plen...</td>\n",
              "      <td>Miles from you   I`m in Essex so give me plent...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>124</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>cd0d522bb1</td>\n",
              "      <td>His snoring is so annoying n it keeps me from ...</td>\n",
              "      <td>His snoring is so annoying n it keeps me from ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>131</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>bffa3ddd61</td>\n",
              "      <td>i miss you bby      wish you were going tomorr...</td>\n",
              "      <td>i miss you bby</td>\n",
              "      <td>negative</td>\n",
              "      <td>68</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>a3de81e1ba</td>\n",
              "      <td>Hi  how are you doing ???  *just joined twitt...</td>\n",
              "      <td>Hi  how are you doing ???  *just joined twitte...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>52</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>61a8e11e8a</td>\n",
              "      <td>CASEY`S GONE?!?! BUT WHY?! So, she piddled a ...</td>\n",
              "      <td>freaked</td>\n",
              "      <td>negative</td>\n",
              "      <td>125</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>fd9fb4f1ad</td>\n",
              "      <td>i realy wanted to go out cause its so nice but...</td>\n",
              "      <td>busy</td>\n",
              "      <td>negative</td>\n",
              "      <td>62</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>d0d3c6f298</td>\n",
              "      <td>cool i wear black most of the time when i go out</td>\n",
              "      <td>cool i wear black most of the time when i go out</td>\n",
              "      <td>neutral</td>\n",
              "      <td>49</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>561b44a42f</td>\n",
              "      <td>have a safe trip joshy poo.......you`ll knock...</td>\n",
              "      <td>safe</td>\n",
              "      <td>positive</td>\n",
              "      <td>71</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>9843c4688e</td>\n",
              "      <td>hahaa your awesomee !</td>\n",
              "      <td>hahaa your awesomee !</td>\n",
              "      <td>positive</td>\n",
              "      <td>22</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>87fbf14655</td>\n",
              "      <td>holy smokes! star trek was freaking awesomeeeee</td>\n",
              "      <td>awesomeeeee</td>\n",
              "      <td>positive</td>\n",
              "      <td>47</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>22d1806fa0</td>\n",
              "      <td>I hate Fallout 3 it keeps making me jump, I`m ...</td>\n",
              "      <td>I hate Fallout 3 it keeps making me jump, I`m ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>120</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>9d2cffd953</td>\n",
              "      <td>I had it! On my itunes, but then I lost all m...</td>\n",
              "      <td>I had it! On my itunes, but then I lost all my...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>54</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>f78761f7ec</td>\n",
              "      <td>What`s with the gloomy weather? The sun must b...</td>\n",
              "      <td>What`s with the gloomy weather? The sun must b...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>134</td>\n",
              "      <td>negative</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>f0460d611d</td>\n",
              "      <td>not well</td>\n",
              "      <td>not well</td>\n",
              "      <td>negative</td>\n",
              "      <td>8</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>6649f3558c</td>\n",
              "      <td>Not a prob hun</td>\n",
              "      <td>Not a prob</td>\n",
              "      <td>positive</td>\n",
              "      <td>15</td>\n",
              "      <td>neutral</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>b495300bbf</td>\n",
              "      <td>those splinters look very painful...but you w...</td>\n",
              "      <td>painful.</td>\n",
              "      <td>negative</td>\n",
              "      <td>85</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>ef74bab7f3</td>\n",
              "      <td>Congrats!  I cuss like that in a matter of mi...</td>\n",
              "      <td>Congrats!  I cuss like that in a matter of min...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>104</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>3e67a75303</td>\n",
              "      <td>Today is going to be a normal day for I hope. ...</td>\n",
              "      <td>Today is going to be a normal day for I hope. ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>135</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>997a62f83f</td>\n",
              "      <td>These kids are terrible! If I was in Good Evan...</td>\n",
              "      <td>terrible!</td>\n",
              "      <td>negative</td>\n",
              "      <td>67</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c3305ab-39fa-4e1b-bfbb-bb0fe7319b73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c3305ab-39fa-4e1b-bfbb-bb0fe7319b73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c3305ab-39fa-4e1b-bfbb-bb0fe7319b73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e8b41750-8c68-445d-b8b4-ae430906381f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8b41750-8c68-445d-b8b4-ae430906381f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e8b41750-8c68-445d-b8b4-ae430906381f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['error'] == 1]\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"textID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"1cbc812ece\",\n          \"9843c4688e\",\n          \"cb4d439ebc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"just in case you wonder, we are really busy today and this coming with with adding tons of new blogs and updates stay tuned\",\n          \" hahaa your awesomee !\",\n          \"fell asleep waiting for my ride!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selected_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"just in case you wonder, we are really busy today and this coming with with adding tons of new blogs and updates stay tuned\",\n          \"hahaa your awesomee !\",\n          \"fell asleep waiting for my ride!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 8,\n        \"max\": 138,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          54,\n          81,\n          120\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicts\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найбільша кількість помилок на neutral класі. На позитивному та негативному кількість помилок значно не відрізняється.  \n",
        "З чим, на мій погляд, можуть бути пов'язані помилки:  \n",
        "- використаний словник стоп слів видалив всі слова, що в лексиці англійської мови явно вказують на заперечення, наприклад, в оригіналі було 'not good', ми прибрали not і, відповідно, рішення моделі базується виключно на слові good, яке має високий коефіцієнт значущості;  \n",
        "- також, я прибрала знаки пунктуації, не врахувавши, що такі послідовності як '!!!!!', '?????', '???!!!!!' тощо можуть впливати на емоційне забарвлення тексту;  \n",
        "- текст капс локом. Це зазвичай також є ознакою емоційного забарвлення, ми нівелювали це препроцесингом;\n",
        "- сленг та загально прийняті скорочення типу 'idk';  \n",
        "- невірно написані слова (з повторенням літер - 'BADDD');\n",
        "- для нейтральних твітів іноді одне єдине слово, що має високий коефіцієнт важливості, спотрворює результат, навіть якщо весь твіт цілком дійсно не несе негативного забарвлення.  \n",
        "\n",
        "Як можна покращити результати:  \n",
        "- створити кастомний список стоп слів\n",
        "- використати ngram_range\n",
        "- можна створити додаткову змінну, в чку записувати частку великих літер в усьому твіті\n",
        "- створити спеціальний словник з розшифровкою скорочень та сленгових слів\n",
        "- використовувати для моделі не text, а selected_text"
      ],
      "metadata": {
        "id": "CqfVckT3Si1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "І на фінал кернел для натхнення і ознайомлення з рішенням оригінальної задачі. Багато цікавих візуалізацій і аналізу є тут, а також тут розвʼязується саме проблема named entitty recognition і можна ознайомитись як це робиться - вона дещо складніша по своїй суті ніж класифікація, подумайте, чому:\n",
        "\n",
        "https://www.kaggle.com/code/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model"
      ],
      "metadata": {
        "id": "lFi4VWwjRS3h"
      }
    }
  ]
}